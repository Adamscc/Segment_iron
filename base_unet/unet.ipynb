{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:20.818675Z",
     "start_time": "2024-09-04T13:30:17.698502Z"
    }
   },
   "source": [
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from time import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:20.829872Z",
     "start_time": "2024-09-04T13:30:20.819675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Unet, self).__init__()\n",
    "        self.stage_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.stage_2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.stage_3 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.stage_4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.stage_5 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.upsample_4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=1024, out_channels=512,kernel_size=4,stride=2, padding=1) \n",
    "        )\n",
    "        self.upsample_3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256,kernel_size=4,stride=2, padding=1) \n",
    "        )\n",
    "        self.upsample_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=128,kernel_size=4,stride=2, padding=1) \n",
    "        )\n",
    "        self.upsample_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128, out_channels=64,kernel_size=4,stride=2, padding=1) \n",
    "        )\n",
    "        \n",
    "        self.stage_up_4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.stage_up_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=256, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )    \n",
    "        \n",
    "        self.stage_up_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        ) \n",
    "        self.stage_up_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )    \n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=3, padding=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        #下采样过程\n",
    "        stage_1 = self.stage_1(x)\n",
    "        stage_2 = self.stage_2(stage_1)\n",
    "        stage_3 = self.stage_3(stage_2)\n",
    "        stage_4 = self.stage_4(stage_3)\n",
    "        stage_5 = self.stage_5(stage_4)\n",
    "        \n",
    "        #1024->512\n",
    "        up_4 = self.upsample_4(stage_5)\n",
    "        #512+512 -> 512\\\n",
    "        \n",
    "        up_4_conv = self.stage_up_4(torch.cat([up_4, stage_4], dim=1))\n",
    "        \n",
    "        #512 -> 256\n",
    "        up_3 = self.upsample_3(up_4_conv)\n",
    "        #256+256 -> 256\n",
    "        up_3_conv = self.stage_up_3(torch.cat([up_3, stage_3], dim=1))\n",
    "        \n",
    "        up_2 = self.upsample_2(up_3_conv)\n",
    "        up_2_conv = self.stage_up_2(torch.cat([up_2, stage_2], dim=1))\n",
    "        \n",
    "        up_1 = self.upsample_1(up_2_conv)\n",
    "        up_1_conv = self.stage_up_1(torch.cat([up_1, stage_1], dim=1))   \n",
    "        \n",
    "        output = self.final(up_1_conv)\n",
    "        \n",
    "        return output"
   ],
   "id": "ca6a690cad0fb2bc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:20.834770Z",
     "start_time": "2024-09-04T13:30:20.829872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SegDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images_dir, masks_dir):\n",
    "        # 使用Albumentations定义变换\n",
    "        self.transforms = A.Compose([\n",
    "            A.Resize(224, 224),  # 调整图像大小\n",
    "            A.HorizontalFlip(),  # 随机水平翻转\n",
    "            A.VerticalFlip(),    # 随机垂直翻转\n",
    "            A.Normalize(),  # 归一化\n",
    "            ToTensorV2()  # 转换为张量\n",
    "        ])\n",
    "        self.ids = os.listdir(images_dir)\n",
    "        # self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
    "        # self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
    "        \n",
    "        # self.images_fps = [os.path.normpath(os.path.join(images_dir, image_id)) for image_id in self.ids]\n",
    "        # self.masks_fps = [os.path.normpath(os.path.join(masks_dir, image_id)) for image_id in self.ids]\n",
    "        self.images_fps = [images_dir+\"/\"+ image_id for image_id in self.ids]\n",
    "        self.masks_fps = [masks_dir+\"/\"+ image_id for image_id in self.ids]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # 使用cv2读取图像\n",
    "        image = cv2.imread(self.images_fps[i])\n",
    "        mask = cv2.imread(self.masks_fps[i].replace(\".jpg\", \".png\"))\n",
    "        # print(\"mask\",mask)\n",
    "        # print(\"image\",image)\n",
    "        # print(self.images_fps[i])\n",
    "        # print(self.masks_fps[i])\n",
    "\n",
    "        # 将图像和掩码从BGR转换为RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        image = np.array(image)\n",
    "        mask = np.array(mask)\n",
    "\n",
    "\n",
    "        # 应用预处理变换\n",
    "        transformed = self.transforms(image=image, mask=mask)\n",
    "\n",
    "        # 返回变换后的图像和掩码（假设掩码是单通道的，选择第一个通道）\n",
    "        return transformed['image'], transformed['mask'][:, :, 0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ],
   "id": "6049071309b7c41d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:20.840410Z",
     "start_time": "2024-09-04T13:30:20.834770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_train_dir = \"NEU_Seg-main/NEU_Seg-main/images/training\"\n",
    "y_train_dir = \"NEU_Seg-main/NEU_Seg-main/annotations/training\"\n",
    "x_test_dir = \"NEU_Seg-main/NEU_Seg-main/images/test\"\n",
    "y_test_dir = \"NEU_Seg-main/NEU_Seg-main/annotations/test\"\n",
    "\n",
    "train_dataset = SegDataset(\n",
    "    x_train_dir, \n",
    "    y_train_dir, \n",
    ")\n",
    "test_dataset = SegDataset(\n",
    "    x_test_dir, \n",
    "    y_test_dir, \n",
    ")"
   ],
   "id": "6cc9407b296bea31",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:20.843645Z",
     "start_time": "2024-09-04T13:30:20.841414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True,drop_last=True)"
   ],
   "id": "91b1946d074b4e54",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:20.853185Z",
     "start_time": "2024-09-04T13:30:20.843645Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_dataset[0])",
   "id": "285d582f060cf3e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-0.9192, -0.9020, -0.9363,  ..., -0.5767, -0.5938, -0.5596],\n",
      "         [-0.9192, -0.9020, -0.9363,  ..., -0.6452, -0.6281, -0.5767],\n",
      "         [-0.9192, -0.9192, -0.9363,  ..., -0.5938, -0.6109, -0.5596],\n",
      "         ...,\n",
      "         [-0.8164, -0.8335, -0.8507,  ..., -0.3369, -0.3541, -0.4226],\n",
      "         [-0.8335, -0.8164, -0.8335,  ..., -0.2856, -0.2856, -0.3198],\n",
      "         [-0.8678, -0.8507, -0.8507,  ..., -0.3027, -0.2856, -0.2342]],\n",
      "\n",
      "        [[-0.8102, -0.7927, -0.8277,  ..., -0.4601, -0.4776, -0.4426],\n",
      "         [-0.8102, -0.7927, -0.8277,  ..., -0.5301, -0.5126, -0.4601],\n",
      "         [-0.8102, -0.8102, -0.8277,  ..., -0.4776, -0.4951, -0.4426],\n",
      "         ...,\n",
      "         [-0.7052, -0.7227, -0.7402,  ..., -0.2150, -0.2325, -0.3025],\n",
      "         [-0.7227, -0.7052, -0.7227,  ..., -0.1625, -0.1625, -0.1975],\n",
      "         [-0.7577, -0.7402, -0.7402,  ..., -0.1800, -0.1625, -0.1099]],\n",
      "\n",
      "        [[-0.5844, -0.5670, -0.6018,  ..., -0.2358, -0.2532, -0.2184],\n",
      "         [-0.5844, -0.5670, -0.6018,  ..., -0.3055, -0.2881, -0.2358],\n",
      "         [-0.5844, -0.5844, -0.6018,  ..., -0.2532, -0.2707, -0.2184],\n",
      "         ...,\n",
      "         [-0.4798, -0.4973, -0.5147,  ...,  0.0082, -0.0092, -0.0790],\n",
      "         [-0.4973, -0.4798, -0.4973,  ...,  0.0605,  0.0605,  0.0256],\n",
      "         [-0.5321, -0.5147, -0.5147,  ...,  0.0431,  0.0605,  0.1128]]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.uint8))\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:21.101010Z",
     "start_time": "2024-09-04T13:30:20.853185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Unet(num_classes=4).to(device)"
   ],
   "id": "b11ffec42a807863",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:11:56.122068Z",
     "start_time": "2024-09-04T13:08:05.521434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()  # 定义损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 优化器\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader, desc=f\"训练轮数 [{epoch + 1}/{num_epochs}]\"):\n",
    "        images, labels = images.to(device), labels.to(device).long()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_accuracy = correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # 测试模型\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device).long()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = correct / total\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "    print(f\"训练集上的loss: {avg_train_loss:.4f} - 训练集上的准确度: {train_accuracy * 100:.2f}%\")\n",
    "    print(f\"测试集上的loss: {avg_test_loss:.4f} - 测试集上的准确度: {test_accuracy * 100:.2f}%\")"
   ],
   "id": "9e9def3fd87e1b25",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮数 [1/10]: 100%|██████████| 226/226 [02:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集上的loss: 0.2609 - 训练集上的准确度: 4580485.37%\n",
      "测试集上的loss: 0.2556 - 测试集上的准确度: 4594756.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮数 [2/10]:  61%|██████    | 137/226 [01:24<00:54,  1.63it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 17\u001B[0m running_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     20\u001B[0m total \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:30:26.272760Z",
     "start_time": "2024-09-04T13:30:26.264261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"Evaluate accuracy of a model on the given data set using a GPU.\"\"\"\n",
    "    if device is None and isinstance(net, nn.Module):\n",
    "        device = next(iter(net.parameters())).device\n",
    "    net.eval()  # Set the model to evaluation mode\n",
    "    metric = [0.0, 0.0]  # Sum of correct predictions, number of predictions\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric[0] += (net(X).argmax(dim=1) == y).float().sum().item()\n",
    "            metric[1] += y.numel()\n",
    "    return metric[0] / metric[1]\n",
    "\n",
    "def train_batch(net, features, labels, loss, trainer, device):\n",
    "    \"\"\"Train a batch of data.\"\"\"\n",
    "    if isinstance(features, list):\n",
    "        features = [x.to(device) for x in features]\n",
    "    else:\n",
    "        features = features.to(device)\n",
    "    labels = labels.to(device)\n",
    "    net.train()\n",
    "    trainer.zero_grad()\n",
    "    predictions = net(features)\n",
    "    l = loss(predictions, labels)\n",
    "    l.backward()\n",
    "    trainer.step()\n",
    "    with torch.no_grad():\n",
    "        acc = (predictions.argmax(dim=1) == labels).float().mean().item()\n",
    "    return l.item(), acc\n",
    "\n",
    "def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, scheduler, devices=None):\n",
    "    if devices is None:\n",
    "        devices = [torch.device('cuda' if torch.cuda.is_available() else 'cpu')]\n",
    "    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n",
    "\n",
    "    loss_list = []\n",
    "    train_acc_list = []\n",
    "    test_acc_list = []\n",
    "    epochs_list = []\n",
    "    time_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        metric = [0.0, 0.0, 0.0, 0.0]  # Sum of training loss, sum of training accuracy, no. of examples, no. of predictions\n",
    "        start_time = time()\n",
    "\n",
    "        # for i, (features, labels) in enumerate(train_iter):\n",
    "        for i, (features, labels) in tqdm(enumerate(train_iter), total=len(train_iter), desc=f\"训练轮数 [{epoch + 1}/{num_epochs}]\"):\n",
    "            l, acc = train_batch(net, features, labels.long(), loss, trainer, devices[0])################################\n",
    "            metric[0] += l * labels.shape[0]\n",
    "            metric[1] += acc * labels.numel()\n",
    "            metric[2] += labels.shape[0]\n",
    "            metric[3] += labels.numel()\n",
    "\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter, devices[0])\n",
    "        scheduler.step()\n",
    "\n",
    "        epoch_time = time() - start_time\n",
    "        print(f\"Epoch {epoch} \\n--- Loss {metric[0] / metric[2]:.3f} \\n---  Train Acc {metric[1] / metric[3]:.3f} \\n--- Test Acc {test_acc:.3f} \\n--- Time {epoch_time:.1f}s\")\n",
    "\n",
    "        # Save training data\n",
    "        loss_list.append(metric[0] / metric[2])\n",
    "        train_acc_list.append(metric[1] / metric[3])\n",
    "        test_acc_list.append(test_acc)\n",
    "        epochs_list.append(epoch)\n",
    "        time_list.append(epoch_time)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            'epoch': epochs_list,\n",
    "            'loss': loss_list,\n",
    "            'train_acc': train_acc_list,\n",
    "            'test_acc': test_acc_list,\n",
    "            'time': time_list\n",
    "        })\n",
    "        df.to_excel(\"savefile/Unet.xlsx\", index=False)\n",
    "\n",
    "        # Save model checkpoints\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save(net.state_dict(), f'checkpoints/Unet_{epoch+1}.pth')\n",
    "\n",
    "# Example usage:\n",
    "# train_ch13(net, train_loader, test_loader, loss_fn, optimizer, num_epochs, scheduler)\n"
   ],
   "id": "21bd6d714c0140d7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T13:42:34.238287Z",
     "start_time": "2024-09-04T13:30:27.092824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 10\n",
    "lossf = nn.CrossEntropyLoss(ignore_index=255)\n",
    "#选用adam优化器来训练\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1, last_epoch=-1)\n",
    "train_ch13(model, train_loader, test_loader, lossf, optimizer, num_epochs, scheduler)"
   ],
   "id": "f98cdc48e5273a85",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮数 [1/10]: 100%|██████████| 226/226 [02:13<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 \n",
      "--- Loss 0.267 \n",
      "---  Train Acc 0.911 \n",
      "--- Test Acc 0.934 \n",
      "--- Time 144.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮数 [2/10]: 100%|██████████| 226/226 [02:15<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      "--- Loss 0.145 \n",
      "---  Train Acc 0.947 \n",
      "--- Test Acc 0.904 \n",
      "--- Time 146.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮数 [3/10]: 100%|██████████| 226/226 [02:15<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 \n",
      "--- Loss 0.116 \n",
      "---  Train Acc 0.956 \n",
      "--- Test Acc 0.954 \n",
      "--- Time 146.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮数 [4/10]: 100%|██████████| 226/226 [02:13<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 \n",
      "--- Loss 0.104 \n",
      "---  Train Acc 0.960 \n",
      "--- Test Acc 0.957 \n",
      "--- Time 144.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练轮数 [5/10]: 100%|██████████| 226/226 [02:14<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 \n",
      "--- Loss 0.096 \n",
      "---  Train Acc 0.962 \n",
      "--- Test Acc 0.955 \n",
      "--- Time 145.6s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory checkpoints does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mSGD(model\u001B[38;5;241m.\u001B[39mparameters(),lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m)\n\u001B[0;32m      5\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mStepLR(optimizer, step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, last_epoch\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 6\u001B[0m \u001B[43mtrain_ch13\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlossf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[8], line 82\u001B[0m, in \u001B[0;36mtrain_ch13\u001B[1;34m(net, train_iter, test_iter, loss, trainer, num_epochs, scheduler, devices)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# Save model checkpoints\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (epoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 82\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcheckpoints/Unet_\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.pth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\Seg\\Lib\\site-packages\\torch\\serialization.py:651\u001B[0m, in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001B[0m\n\u001B[0;32m    648\u001B[0m _check_save_filelike(f)\n\u001B[0;32m    650\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m--> 651\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_zipfile_writer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[0;32m    652\u001B[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001B[0;32m    653\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\Seg\\Lib\\site-packages\\torch\\serialization.py:525\u001B[0m, in \u001B[0;36m_open_zipfile_writer\u001B[1;34m(name_or_buffer)\u001B[0m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    524\u001B[0m     container \u001B[38;5;241m=\u001B[39m _open_zipfile_writer_buffer\n\u001B[1;32m--> 525\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcontainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\Seg\\Lib\\site-packages\\torch\\serialization.py:496\u001B[0m, in \u001B[0;36m_open_zipfile_writer_file.__init__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    494\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mPyTorchFileWriter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_stream))\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 496\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPyTorchFileWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Parent directory checkpoints does not exist."
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-04T12:50:26.446256Z",
     "start_time": "2024-09-04T12:50:26.442289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pc = cv2.imread(\"NEU_Seg-main/NEU_Seg-main/images/training/000201.jpg\")\n",
    "print(np.array(pc))"
   ],
   "id": "db9f74a6cd95b2b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 73  73  73]\n",
      "  [ 74  74  74]\n",
      "  [ 74  74  74]\n",
      "  ...\n",
      "  [106 106 106]\n",
      "  [107 107 107]\n",
      "  [110 110 110]]\n",
      "\n",
      " [[ 76  76  76]\n",
      "  [ 76  76  76]\n",
      "  [ 75  75  75]\n",
      "  ...\n",
      "  [107 107 107]\n",
      "  [107 107 107]\n",
      "  [104 104 104]]\n",
      "\n",
      " [[ 76  76  76]\n",
      "  [ 75  75  75]\n",
      "  [ 74  74  74]\n",
      "  ...\n",
      "  [104 104 104]\n",
      "  [102 102 102]\n",
      "  [ 98  98  98]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 70  70  70]\n",
      "  [ 70  70  70]\n",
      "  [ 68  68  68]\n",
      "  ...\n",
      "  [ 91  91  91]\n",
      "  [ 89  89  89]\n",
      "  [ 92  92  92]]\n",
      "\n",
      " [[ 70  70  70]\n",
      "  [ 71  71  71]\n",
      "  [ 69  69  69]\n",
      "  ...\n",
      "  [ 86  86  86]\n",
      "  [ 86  86  86]\n",
      "  [ 90  90  90]]\n",
      "\n",
      " [[ 70  70  70]\n",
      "  [ 71  71  71]\n",
      "  [ 69  69  69]\n",
      "  ...\n",
      "  [ 90  90  90]\n",
      "  [ 89  89  89]\n",
      "  [ 91  91  91]]]\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "759e303102f78f2d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
